{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4182df6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8705d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d496368",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Twitter dataset\n",
    "df = pd.read_csv('/Users/diegolemos/Masters/Theses/code/data/raw/twcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811774, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying basic informations from the dataset\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694cd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0\n",
       "author_id                        0\n",
       "inbound                          0\n",
       "created_at                       0\n",
       "text                             0\n",
       "response_tweet_id          1040629\n",
       "in_response_to_tweet_id     794335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fce233",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "As we can see above, there are a significative amount of 'response_tweet_id' and 'in_response_to_tweet_id', these missing values indicates tweets that are no part of a reply chain. For now we are going to keep them, and use these columns to recostruct conversations threads. Instead of removing or imputing them, we going to these nulls as anchor points to reconstruct complete conversation chains, by using backward traversal. This will enable us to create a new thread_id column that groups all related tweets together, which is essential for tracking customer sentiment progression across interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c9942",
   "metadata": {},
   "source": [
    "## Conversation Thread Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29160d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing conversation threads\n",
    "\n",
    "# Creating a luokup for parent tweet IDs\n",
    "id_to_parent = dict(zip(df['tweet_id'], df['in_response_to_tweet_id']))\n",
    "\n",
    "# Tracing the root tweet ( Finding the start od the conversation)\n",
    "def find_root_tweet(tweet_id, id_to_parent_cache):\n",
    "    while pd.notnull(id_to_parent_cache.get(tweet_id)):\n",
    "        tweet_id = id_to_parent_cache[tweet_id]\n",
    "    return tweet_id\n",
    "\n",
    "# Applting to all tweets\n",
    "thread_ids = []\n",
    "for tweet_id in df['tweet_id']:\n",
    "    thread_id = find_root_tweet(tweet_id, id_to_parent)\n",
    "    thread_ids.append(thread_id)\n",
    "\n",
    "df['thread_id'] = thread_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd2c8c",
   "metadata": {},
   "source": [
    "### Reconstructing conversation threads\n",
    "To understand how the messages are connected into conversation, I utilised thread_id which groups all the tweets belonging to the same conversation, with the in_response_to_tweet_id column, I was able to follow the responses back to the original tweet of a thread. This is the relation using which we will backtrack to the genesis of every tweet. We use this ID as thread_id and this way we are able to group messages belong to same support interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97876d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique threads:  798012\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of unique threads\n",
    "print('Unique threads: ', df['thread_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72b7da",
   "metadata": {},
   "source": [
    "## Customer Message Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8761c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inbound\n",
       "True     1537843\n",
       "False    1273931\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking amount of messages from customer (True) and agents (False)\n",
    "df['inbound'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1676f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering customer messages\n",
    "customer_df = df[df['inbound'] == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ef8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@AmazonHelp it took you 8 hours to figure that out when i had already mentioned that. both the products are billed in my name and i have provided the...',\n",
       " '@115913 I would like to private message you how would I go about that',\n",
       " '@AmazonHelp We have also replay on this link please check and get back update me ASAP',\n",
       " '@115955 - keep making those silly commercials w the dummy, they r a scream!',\n",
       " \"@AppleSupport I'm so mad ðŸ˜¡ðŸ˜¡ðŸ˜¡ My past iMessages are deleted. Why??????\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with no text\n",
    "customer_df.dropna(subset = ['text'], inplace = True)\n",
    "customer_df = customer_df[customer_df['text'].str.strip() != '']\n",
    "\n",
    "# Displaying samples\n",
    "customer_df['text'].sample(5).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161011c4",
   "metadata": {},
   "source": [
    "### Customers Inbound\n",
    "Here we have created a copy from the dataset containing only constumer messages as the objective of this project is to detect customer dissarisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f7b8c",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e4cfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Removing mentions and hastags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Removing extra space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Creating a function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4540c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning customer messagaes\n",
    "customer_df['clean_text'] = customer_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6c28a",
   "metadata": {},
   "source": [
    "## Language Detection & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c83e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting lamguage\n",
    "customer_df['lang'] = customer_df['clean_text'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31335333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only  for English messages\n",
    "customer_df = customer_df[customer_df['lang'] == 'en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45a5e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1019430</th>\n",
       "      <td>@AmericanAir It's stressful enough flying with...</td>\n",
       "      <td>It's stressful enough flying with cancer this ...</td>\n",
       "      <td>386091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30397</th>\n",
       "      <td>The crooks @115873 trying to charge me almost ...</td>\n",
       "      <td>The crooks trying to charge me almost $100 for...</td>\n",
       "      <td>124491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398443</th>\n",
       "      <td>@222781 @XboxSupport I got banned for calling ...</td>\n",
       "      <td>I got banned for calling someone \"awful\" using...</td>\n",
       "      <td>222780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074308</th>\n",
       "      <td>@AmericanAir not yet! The #coffeedebacle is st...</td>\n",
       "      <td>not yet! The is still a debacle, but I'm on th...</td>\n",
       "      <td>396735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569094</th>\n",
       "      <td>@sainsburys is it really necessary to have you...</td>\n",
       "      <td>is it really necessary to have your packaging ...</td>\n",
       "      <td>767667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "1019430  @AmericanAir It's stressful enough flying with...   \n",
       "30397    The crooks @115873 trying to charge me almost ...   \n",
       "398443   @222781 @XboxSupport I got banned for calling ...   \n",
       "1074308  @AmericanAir not yet! The #coffeedebacle is st...   \n",
       "2569094  @sainsburys is it really necessary to have you...   \n",
       "\n",
       "                                                clean_text author_id  \n",
       "1019430  It's stressful enough flying with cancer this ...    386091  \n",
       "30397    The crooks trying to charge me almost $100 for...    124491  \n",
       "398443   I got banned for calling someone \"awful\" using...    222780  \n",
       "1074308  not yet! The is still a debacle, but I'm on th...    396735  \n",
       "2569094  is it really necessary to have your packaging ...    767667  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printting sample with cleanned messages\n",
    "customer_df[['text', 'clean_text', 'author_id']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3bfc7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the proessed dataset\n",
    "customer_df.to_csv('/Users/diegolemos/Masters/Theses/code/data/processed/customer_english.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd36df2",
   "metadata": {},
   "source": [
    "### Clean text and language detection\n",
    "In this step, we have cleaned the raw tweet texts by removing unnecessary elements such as URLs, mentions, hashtags nd extra space. Numbers, punctuation and emojis were kept as it can have important impact on the sentiment impressed in a message. We also have created a new column called 'clean_text' that recieves this clean text. This ensures that the data is ready for tokenisation and sentiment analysis.\n",
    "\n",
    "Additionally, we have implemented a function to detect the language of the message, further, filtering for Eglish leaguage only, as models like VADER and SistilBERT are very English-centic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
