{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f333a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import IPython.display as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4dadf",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>Feature Type</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LOGREG</td>\n",
       "      <td>Raw Text</td>\n",
       "      <td>logreg_tfidf_results_80_20</td>\n",
       "      <td>75.07</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.7587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Bilstm</td>\n",
       "      <td>bilstm_results_70_30</td>\n",
       "      <td>83.85</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>0.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Bilstm</td>\n",
       "      <td>bilstm_results_75_25</td>\n",
       "      <td>84.45</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.8206</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.8478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Bilstm</td>\n",
       "      <td>bilstm_results_80_20</td>\n",
       "      <td>84.07</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Logreg</td>\n",
       "      <td>logreg_results_5fold</td>\n",
       "      <td>57.40</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Logreg</td>\n",
       "      <td>logreg_results_70_30</td>\n",
       "      <td>46.36</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.4248</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Logreg</td>\n",
       "      <td>logreg_results_75_25</td>\n",
       "      <td>50.66</td>\n",
       "      <td>0.3324</td>\n",
       "      <td>0.3326</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.4183</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.4342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Logreg</td>\n",
       "      <td>logreg_results_80_20</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Rf</td>\n",
       "      <td>rf_results_5fold</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.3530</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.2423</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Rf</td>\n",
       "      <td>rf_results_70_30</td>\n",
       "      <td>56.98</td>\n",
       "      <td>0.3951</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Rf</td>\n",
       "      <td>rf_results_75_25</td>\n",
       "      <td>56.97</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Rf</td>\n",
       "      <td>rf_results_80_20</td>\n",
       "      <td>56.97</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Svm</td>\n",
       "      <td>sgd_svm_results_5fold</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>0.3183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Svm</td>\n",
       "      <td>sgd_svm_results_70_30</td>\n",
       "      <td>43.10</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.4184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Svm</td>\n",
       "      <td>sgd_svm_results_75_25</td>\n",
       "      <td>50.57</td>\n",
       "      <td>0.3311</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Svm</td>\n",
       "      <td>sgd_svm_results_80_20</td>\n",
       "      <td>48.62</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF</td>\n",
       "      <td>Raw Text</td>\n",
       "      <td>rf_tfidf_results_80_20</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM</td>\n",
       "      <td>Raw Text</td>\n",
       "      <td>svm_tfidf_results_80_20</td>\n",
       "      <td>75.12</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.7463</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.7481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Path to results directory\n",
    "base_dir = \"../results\"\n",
    "\n",
    "#Output list\n",
    "rows = []\n",
    "\n",
    "#Walking through all results subfolders\n",
    "for root, _, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            #Loading JSON files\n",
    "            with open(file_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            #Extracting metrics\n",
    "            accuracy = round(data.get(\"accuracy\", 0) * 100, 2)\n",
    "            macro = data.get(\"macro avg\", {})\n",
    "            weighted = data.get(\"weighted avg\", {})\n",
    "\n",
    "            macro_precision = round(macro.get(\"precision\", 0), 4)\n",
    "            macro_recall = round(macro.get(\"recall\", 0), 4)\n",
    "            macro_f1 = round(macro.get(\"f1-score\", 0), 4)\n",
    "\n",
    "            weighted_precision = round(weighted.get(\"precision\", 0), 4)\n",
    "            weighted_recall = round(weighted.get(\"recall\", 0), 4)\n",
    "            weighted_f1 = round(weighted.get(\"f1-score\", 0), 4)\n",
    "\n",
    "            #Parse model name, feature type, and split from the path\n",
    "            parts = root.split(os.sep)\n",
    "            model = parts[-2] if len(parts) >= 2 else \"Unknown\"\n",
    "            feature_type = parts[-1] if model != parts[-1] else \"Default\"\n",
    "            split_info = file.replace(\".json\", \"\").replace(f\"{model}_results_\", \"\")\n",
    "\n",
    "            #Appending the rows\n",
    "            rows.append({\n",
    "                \"Model\": model.upper(),\n",
    "                \"Feature Type\": feature_type.replace(\"_\", \" \").title(),\n",
    "                \"Split\": split_info,\n",
    "                \"Accuracy (%)\": accuracy,\n",
    "                \"Macro Precision\": macro_precision,\n",
    "                \"Macro Recall\": macro_recall,\n",
    "                \"Macro F1\": macro_f1,\n",
    "                \"Weighted Precision\": weighted_precision,\n",
    "                \"Weighted Recall\": weighted_recall,\n",
    "                \"Weighted F1\": weighted_f1\n",
    "            })\n",
    "\n",
    "#Creating DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values(by=[\"Model\", \"Feature Type\", \"Split\"])\n",
    "\n",
    "#Displaying\n",
    "dp.display(dp.HTML(df.to_html(index=False)))\n",
    "\n",
    "#Saving to CSV\n",
    "df.to_csv(\"summary_results_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3198378",
   "metadata": {},
   "source": [
    "### Results Summary Table\n",
    "In the last notebook, we gathered the results of all the models, which we considered during all the project into one comparison table. Traditional machine learning based on both reduced PCA-based embeddings and raw text features, and neural networks deep learning based on BiLSTM model.\n",
    "\n",
    "As the table indicates, raw text features were always outperforming the reduced PCA BERT embeddings trained model in terms of all metrics. Random Forest and SVM are leading models among traditional ones and their performance was competitive when employing TF-IDF features, and Logistic Regression demonstrated similar stability by class. But the BiLSTM model was different, as it produced the best overall outcomes, due to the opportunity to use both sequential and contextual information.\n",
    "\n",
    "Such comparison confirms choices made at the stage of experimental work and proves the idea of working with BiLSTM model in the ultimate evaluation fairly well. It also demonstrates the fact that selection of feature representation can have a dramatic effect on model performance a topic that will be explained in detail in the thesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
